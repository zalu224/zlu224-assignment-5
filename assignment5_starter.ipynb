{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "UxDj47wboGyh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "4hzjwcC0oGyi"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # TODO: Implement the fit method\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        # pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        # TODO: Implement the predict method\n",
        "        # pass\n",
        "        return np.array([self._predict(x) for x in X])\n",
        "\n",
        "    def _predict(self, x):\n",
        "        distances = self.compute_distance(x, self.X_train)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "        return np.bincount(k_nearest_labels).argmax()\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        # TODO: Implement distance computation based on self.distance_metric\n",
        "        # Hint: Use numpy operations for efficient computation\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X2 - X1)**2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X2 - X1), axis=1)\n",
        "        elif self.distance_metric == 'minkowski':\n",
        "            p = 5 # adjustable\n",
        "            return np.power(np.sum(np.abs(X2 - X1)**p, axis=1), 1/p)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "        # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "HFdJ79VloGyj"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # TODO: Implement data preprocessing\n",
        "    # Ensure we're working with all test data rows\n",
        "    print(f\"Number of rows in test data: {len(test_data)}\")\n",
        "\n",
        "    all_data = pd.concat([train_data, test_data], axis=0, sort=False)\n",
        "\n",
        "    # Handle categorical variables\n",
        "    all_data = pd.get_dummies(all_data, columns=['Geography', 'Gender'], drop_first=False)\n",
        "\n",
        "    # Feature engineering\n",
        "    all_data['BalanceToSalary'] = all_data['Balance'] / (all_data['EstimatedSalary'] + 1)\n",
        "    all_data['ProductsPerTenure'] = all_data['NumOfProducts'] / (all_data['Tenure'] + 1)\n",
        "    all_data['CreditScoreToAge'] = all_data['CreditScore'] / (all_data['Age'] + 1)\n",
        "    all_data['BalancePerProduct'] = all_data['Balance'] / (all_data['NumOfProducts'] + 1)\n",
        "    all_data['AgeGroup'] = pd.cut(all_data['Age'], bins=[0, 30, 45, 60, 100], labels=[0, 1, 2, 3]).astype(int)\n",
        "\n",
        "    # Select features and assign weights\n",
        "    features_and_weights = {\n",
        "        'Age': 2.5, 'Tenure': 4.0, 'Balance': 2.0, 'NumOfProducts': 3.5,\n",
        "        'IsActiveMember': 5.0, 'CreditScore': 2.0, 'EstimatedSalary': 1.5,\n",
        "        'HasCrCard': 1.5, 'Geography_France': 1.0, 'Geography_Germany': 1.0,\n",
        "        'Geography_Spain': 1.0, 'Gender_Male': 1.0, 'BalanceToSalary': 3.0,\n",
        "        'ProductsPerTenure': 4.0, 'CreditScoreToAge': 2.5, 'BalancePerProduct': 3.0,\n",
        "        'AgeGroup': 2.0,\n",
        "    }\n",
        "\n",
        "    features = list(features_and_weights.keys())\n",
        "\n",
        "    # Impute and scale\n",
        "    for feature in features:\n",
        "        if feature != 'AgeGroup':\n",
        "            all_data[feature] = all_data[feature].fillna(all_data[feature].median())\n",
        "            all_data[feature] = (all_data[feature] - all_data[feature].mean()) / all_data[feature].std()\n",
        "\n",
        "    # Apply feature weights\n",
        "    for feature, weight in features_and_weights.items():\n",
        "        all_data[feature] *= weight\n",
        "\n",
        "    # Split back into train and test\n",
        "    X = all_data[features].iloc[:len(train_data)].values\n",
        "    y = train_data['Exited'].astype(int).values\n",
        "    X_test = all_data[features].iloc[len(train_data):].values\n",
        "\n",
        "    return X, y, X_test, test_data[['id', 'CustomerId']].values, features\n",
        "\n",
        "\n",
        "    # def mutual_info_score(X, y):\n",
        "    #     y = y.reshape(-1, 1)\n",
        "    #     y_counts = np.bincount(y.ravel())\n",
        "    #     y_probs = y_counts / len(y)\n",
        "    #     y_entropy = -np.sum(y_probs * np.log2(y_probs + 1e-10))\n",
        "\n",
        "    #     mi_scores = []\n",
        "    #     for col in X.T:\n",
        "    #         bins = np.histogram_bin_edges(col, bins='auto')\n",
        "    #         xy_counts = np.histogram2d(col, y.ravel(), bins=(bins, [0, 1, 2]))[0]\n",
        "    #         xy_probs = xy_counts / len(y)\n",
        "    #         x_probs = xy_probs.sum(axis=1)\n",
        "    #         y_probs = xy_probs.sum(axis=0)\n",
        "\n",
        "    #         mi = np.sum(xy_probs * np.log2(xy_probs / (x_probs[:, None] * y_probs[None, :]) + 1e-10))\n",
        "    #         mi_scores.append(mi)\n",
        "\n",
        "    #     return np.array(mi_scores)\n",
        "\n",
        "    # mi_scores = mutual_info_score(X, y)\n",
        "    # selected_features = [features[i] for i in np.argsort(mi_scores)[-8:]]  # Select top 8 features\n",
        "\n",
        "    # # Split back into train and test\n",
        "    # X = all_data[selected_features].iloc[:len(train_data)].values\n",
        "    # y = train_data['Exited'].astype(int).values  # Convert to int\n",
        "    # X_test = all_data[selected_features].iloc[len(train_data):].values\n",
        "\n",
        "    # return X, y, X_test, all_data['CustomerId'].iloc[len(train_data):].values, selected_features\n",
        "\n",
        "    # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "bJOlhS4foGyj"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # TODO: Implement cross-validation\n",
        "    # Compute ROC AUC scores\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    fold_size = len(X) // n_splits\n",
        "\n",
        "    scores = []\n",
        "    for i in range(n_splits):\n",
        "        start = i * fold_size\n",
        "        end = (i + 1) * fold_size if i < n_splits - 1 else len(X)\n",
        "\n",
        "        test_indices = indices[start:end]\n",
        "        train_indices = np.concatenate([indices[:start], indices[end:]])\n",
        "\n",
        "        X_train, X_val = X[train_indices], X[test_indices]\n",
        "        y_train, y_val = y[train_indices], y[test_indices]\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        predictions = knn.predict(X_val)\n",
        "\n",
        "        score = np.mean(predictions == y_val)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)\n",
        "    # pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezdKxL1noGyj",
        "outputId": "00edd2fc-69b8-4751-9fbf-054bc6b60ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in test data: 10000\n",
            "k=28, metric=euclidean, score=0.8836666666666666\n",
            "k=28, metric=manhattan, score=0.8862666666666665\n",
            "Best hyperparameters: k=28, metric=manhattan, score=0.8862666666666665\n",
            "Number of predictions: 10000\n",
            "Number of unique IDs: 10000\n",
            "Saved 10000 unique predictions to submissions.csv\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test, test_ids, selected_features = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "# # Create and evaluate model\n",
        "# knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# # Perform cross-validation\n",
        "# cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "# print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# TODO: hyperparamters tuning\n",
        "# Hyperparameter tuning\n",
        "k_values = [28]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "\n",
        "best_score = 0\n",
        "best_k = 0\n",
        "best_metric = ''\n",
        "\n",
        "for k in k_values:\n",
        "    for metric in distance_metrics:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        score = cross_validate(X, y, knn)\n",
        "        print(f\"k={k}, metric={metric}, score={score}\")\n",
        "\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_k = k\n",
        "            best_metric = metric\n",
        "\n",
        "print(f\"Best hyperparameters: k={best_k}, metric={best_metric}, score={best_score}\")\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "# Train on full dataset with optimal hyperparameters\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Create submissions DataFrame\n",
        "submissions_df = pd.DataFrame({'id': test_ids[:, 0], 'CustomerId': test_ids[:, 1], 'Exited': test_predictions})\n",
        "submissions_df = submissions_df.sort_values('id')\n",
        "\n",
        "# Verify we have 10,000 unique predictions\n",
        "print(f\"Number of predictions: {len(submissions_df)}\")\n",
        "print(f\"Number of unique IDs: {submissions_df['id'].nunique()}\")\n",
        "\n",
        "# Save test predictions\n",
        "submissions_df[['id', 'Exited']].to_csv('submissions.csv', index=False)\n",
        "\n",
        "print(f\"Saved {len(submissions_df)} unique predictions to submissions.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gM1fRxI9EQWt"
      },
      "execution_count": 186,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}